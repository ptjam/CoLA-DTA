import os
import random
import torch
from argparse import Namespace
from torch_geometric.loader import DataLoader

from models.dta_model import DTARegressionModel
from models.dta_model_no_cross_attention import DTARegressionModelNoCrossAttention
from models.dta_model_no_fusion import DTARegressionModelNoFusion
from models.dta_model_no_protein_graph import DTARegressionModelNoProteinGraph
from models.dta_model_no_compound_graph import DTARegressionModelWithoutCompoundGraph
from dataset.cpidataset import CPIDataset, collate_fn
from pipeline.experiment import DTAExperiment


# ==================== å·¥å…·å‡½æ•° ====================

def set_seed(seed):
    torch.manual_seed(seed)
    random.seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    print(f"ğŸ² Seed set to {seed}\n")


# ==================== ç¡¬ç¼–ç æ•°æ®é›†å®šä¹‰ ====================

datasets = [
    {"name": "DAVIS"},
    {"name": "KIBA"},
    {"name": "BDB"},
    {"name": "PDB"},
    {"name": "PDB_cold_start"}
]

seeds = [42]


# ==================== åŠ è½½æ•°æ®é›†å’ŒDataLoader ====================

def load_dataloader(dataset_name, batch_size=8):
    """
    æ ¹æ®ç»™å®šçš„æ•°æ®é›†åç§°ï¼ŒåŠ è½½å¯¹åº”çš„ DataLoaderï¼Œå¹¶è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ª DataLoaderã€‚
    :param dataset_name: æ•°æ®é›†åç§°ï¼ˆå¦‚ 'DAVIS', 'KIBA', 'BDB', 'PDB', 'PDB_cold_start'ï¼‰
    :param batch_size: æ‰¹æ¬¡å¤§å°
    """
    # ç¡¬ç¼–ç è·¯å¾„
    file_paths = {
        "DAVIS": {
            "train": 'data/DAVIS/standard/train.tsv',
            "val": 'data/DAVIS/standard/val.tsv',
            "test": 'data/DAVIS/standard/test.tsv',
            "protein_graph": 'data/DAVIS/protein_graph',
            "compound_graph": 'data/DAVIS/compound_graphs',
            "protein_feat": 'data/DAVIS/protein_esm_feature.pkl',
            "compound_feat": 'data/DAVIS/compound_bert_features.pkl'
        },
        "KIBA": {
            "train": 'data/KIBA/standard/train.tsv',
            "val": 'data/KIBA/standard/val.tsv',
            "test": 'data/KIBA/standard/test.tsv',
            "protein_graph": 'data/KIBA/protein_graph',
            "compound_graph": 'data/KIBA/compound_graphs',
            "protein_feat": 'data/KIBA/protein_esm_feature.pkl',
            "compound_feat": 'data/KIBA/compound_bert_features.pkl'
        },
        "BDB": {
            "train": 'data/BDB/standard/train.tsv',
            "val": 'data/BDB/standard/val.tsv',
            "test": 'data/BDB/standard/test.tsv',
            "protein_graph": 'data/BDB/protein_graph',
            "compound_graph": 'data/BDB/compound_graphs',
            "protein_feat": 'data/BDB/protein_esm_feature.pkl',
            "compound_feat": 'data/BDB/compound_bert_features.pkl'
        },
        "PDB": {
            "train": 'data/PDB/standard/train.tsv',
            "val": 'data/PDB/standard/val.tsv',
            "test": 'data/PDB/standard/val.tsv',
            "protein_graph": 'data/PDB/protein_graph',
            "compound_graph": 'data/PDB/compound_graphs',
            "protein_feat": 'data/PDB/protein_esm_feature.pkl',
            "compound_feat": 'data/PDB/compound_bert_features.pkl'
        },
        "PDB_cold_start": {
            "train": 'data/PDB/cold_start/train.tsv',
            "cold_protein": 'data/PDB/cold_start/cold_protein.tsv',
            "cold_drug": 'data/PDB/cold_start/cold_drug.tsv',
            "cold_all": 'data/PDB/cold_start/cold_all.tsv',
            "protein_graph": 'data/PDB/protein_graph',
            "compound_graph": 'data/PDB/compound_graphs',
            "protein_feat": 'data/PDB/protein_esm_feature.pkl',
            "compound_feat": 'data/PDB/compound_bert_features.pkl'
        }
    }

    if dataset_name not in file_paths:
        raise ValueError(f"Unknown dataset name: {dataset_name}")

    paths = file_paths[dataset_name]

    if dataset_name == "PDB_cold_start":
        # è¿”å›å››ä¸ª cold-start DataLoader
        train_dataset = CPIDataset(paths["train"], paths["protein_graph"], paths["compound_graph"],
                                   paths["protein_feat"], paths["compound_feat"], preload=True)
        cold_protein_dataset = CPIDataset(paths["cold_protein"], paths["protein_graph"], paths["compound_graph"],
                                          paths["protein_feat"], paths["compound_feat"], preload=True)
        cold_drug_dataset = CPIDataset(paths["cold_drug"], paths["protein_graph"], paths["compound_graph"],
                                       paths["protein_feat"], paths["compound_feat"], preload=True)
        cold_all_dataset = CPIDataset(paths["cold_all"], paths["protein_graph"], paths["compound_graph"],
                                      paths["protein_feat"], paths["compound_feat"], preload=True)

        print(f"ğŸ”„ Preloading {dataset_name} dataset (cold-start) ...")
        print(f"âœ… {dataset_name} - train dataset size: {len(train_dataset)} samples")
        print(f"âœ… {dataset_name} - cold_protein dataset size: {len(cold_protein_dataset)} samples")
        print(f"âœ… {dataset_name} - cold_drug dataset size: {len(cold_drug_dataset)} samples")
        print(f"âœ… {dataset_name} - cold_all dataset size: {len(cold_all_dataset)} samples")

        return {
            "train": DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn),
            "cold_protein": DataLoader(cold_protein_dataset, batch_size=batch_size, collate_fn=collate_fn),
            "cold_drug": DataLoader(cold_drug_dataset, batch_size=batch_size, collate_fn=collate_fn),
            "cold_all": DataLoader(cold_all_dataset, batch_size=batch_size, collate_fn=collate_fn)
        }

    # æ ‡å‡†æ¨¡å¼ï¼štrain, val, test
    train_dataset = CPIDataset(paths["train"], paths["protein_graph"], paths["compound_graph"], paths["protein_feat"],
                               paths["compound_feat"], preload=True)
    val_dataset = CPIDataset(paths["val"], paths["protein_graph"], paths["compound_graph"], paths["protein_feat"],
                             paths["compound_feat"], preload=True)
    test_dataset = CPIDataset(paths["test"], paths["protein_graph"], paths["compound_graph"], paths["protein_feat"],
                              paths["compound_feat"], preload=True)

    print(f"ğŸ”„ Preloading {dataset_name} dataset (standard) ...")
    print(f"âœ… {dataset_name} - train dataset size: {len(train_dataset)} samples")
    print(f"âœ… {dataset_name} - val dataset size: {len(val_dataset)} samples")
    print(f"âœ… {dataset_name} - test dataset size: {len(test_dataset)} samples")

    return {
        "train": DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn),
        "val": DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn),
        "test": DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)
    }


# ==================== ç»Ÿä¸€è®­ç»ƒé€»è¾‘ ====================

def run_experiment(config, dataset_name, seed, model, dataloaders):
    print(f"\nğŸš€ ===== Running experiment for {dataset_name} with seed {seed} =====")

    # è®¾ç½®éšæœºç§å­
    set_seed(seed)

    train_cfg = config['training']
    batch_size = train_cfg['batch_size']
    epochs = train_cfg['epochs']
    lr = train_cfg['lr']
    weight_decay = train_cfg['weight_decay']
    lr_scheduler_patience = train_cfg.get('lr_scheduler_patience', 20)
    early_stopping_patience = train_cfg.get('early_stopping_patience', 30)

    # è·å–æ¨¡å‹çš„åç§°ï¼Œå¹¶æ ¹æ®æ­¤ä¿®æ”¹ä¿å­˜è·¯å¾„
    model_class_name = model.__class__.__name__
    experiment_name = f"{dataset_name}_{model_class_name}_seed{seed}"

    # åŠ¨æ€ç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºè·¯å¾„
    model_output_dir = os.path.join(config['output']['output_dir'], model_class_name, experiment_name)
    os.makedirs(model_output_dir, exist_ok=True)

    # æ›´æ–°é…ç½®
    experiment_config = Namespace(
        seed=seed,
        name=experiment_name,
        dataset=dataset_name,
        model_class=model.__class__,
        train_loader=dataloaders["train"],
        val_loader=dataloaders["val"] if dataset_name != "PDB_cold_start" else None,
        test_loader=dataloaders["test"] if dataset_name != "PDB_cold_start" else None,
        cold_protein_loader=dataloaders["cold_protein"] if dataset_name == "PDB_cold_start" else None,
        cold_drug_loader=dataloaders["cold_drug"] if dataset_name == "PDB_cold_start" else None,
        cold_all_loader=dataloaders["cold_all"] if dataset_name == "PDB_cold_start" else None,
        batch_size=batch_size,
        epochs=epochs,
        lr=lr,
        weight_decay=weight_decay,
        lr_scheduler_patience=lr_scheduler_patience,
        early_stopping_patience=early_stopping_patience,
        collate_fn=collate_fn,
        output_dir=model_output_dir,  # ä½¿ç”¨æ–°çš„æ¨¡å‹è¾“å‡ºç›®å½•
        resume_path=None
    )

    # åˆ›å»ºå¹¶è¿è¡Œå®éªŒ
    if (dataset_name != 'PDB_cold_start'):
        experiment = DTAExperiment(experiment_config, model, train_loader=dataloaders["train"],
                                   val_loader=dataloaders["val"], test_loader=dataloaders["test"])
        experiment.train()
        experiment.evaluate_final()
    else:
        experiment = DTAExperiment(experiment_config, model, train_loader=dataloaders["train"],
                                   cold_all_loader=dataloaders["cold_all"],
                                   cold_protein_loader=dataloaders["cold_protein"],
                                   cold_drug_loader=dataloaders["cold_drug"])
        experiment.train()
        experiment.evaluate_final()


# ==================== ä¸»æ§å…¥å£ ====================

if __name__ == '__main__':
    # é…ç½®ç¡¬ç¼–ç 
    config = {
        'training': {
            'batch_size': 256,
            'epochs': 200,
            'lr': 0.001,
            'weight_decay': 0.00001,
            'lr_scheduler': 'plateau',
            'lr_scheduler_patience': 10,
            'early_stopping_patience': 20
        },
        'output': {
            'output_dir': 'saved_models/ablation_study',
            'model_dir': 'checkpoints/ablation_study',
            'log_dir': 'logs',
            'save_best_only': True
        }
    }

    # ä½ å¯ä»¥åœ¨è¿™é‡Œå¯¼å…¥å¤šä¸ªæ¨¡å‹ï¼Œå¦‚ï¼š
    models = [
        DTARegressionModel,
        DTARegressionModelNoCrossAttention,
        DTARegressionModelNoFusion,
        DTARegressionModelNoProteinGraph,
        DTARegressionModelWithoutCompoundGraph,
    ]

    # éå†æ•°æ®é›†å¹¶æ‰§è¡Œå®éªŒ
    for ds in datasets:
        for seed in seeds:
            print(f"\nğŸš€ ===== Running experiment for {ds['name']} with seed {seed} =====")

            # è·å–å½“å‰æ•°æ®é›†çš„åç§°
            dataset_name = ds['name']

            # åŠ è½½æ•°æ®é›†å’ŒDataLoader
            dataloaders = load_dataloader(dataset_name, batch_size=config['training']['batch_size'])

            # é’ˆå¯¹æ¯ä¸ªæ¨¡å‹ï¼Œé€ä¸ªæ‰§è¡Œè®­ç»ƒå’Œè¯„ä¼°
            for model in models:
                # ç›´æ¥å®ä¾‹åŒ–æ¨¡å‹ï¼ˆæ— éœ€ä¼ é€’ä»»ä½•è¶…å‚æ•°ï¼‰
                model_instance = model()  # ç›´æ¥è°ƒç”¨ï¼Œæ— éœ€ä¼ é€’å‚æ•°
                # æ‰§è¡Œå®éªŒ
                run_experiment(config, dataset_name, seed, model_instance, dataloaders)

    print("\nğŸ‰ All experiments finished successfully.\n")
