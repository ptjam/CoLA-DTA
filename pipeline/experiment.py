import os
import random
import torch
import datetime
import csv
from torch.optim.lr_scheduler import ReduceLROnPlateau  # ç”¨äºå­¦ä¹ ç‡è¡°å‡
from tqdm import tqdm  # ç”¨äºè¿›åº¦æ¡

from pipeline.trainer import Trainer  # å¯¼å…¥ Trainer ç±»
from pipeline.evaluator import Evaluator  # å¯¼å…¥ Evaluator ç±»


class DTAExperiment:
    def __init__(self, config, model, train_loader, val_loader=None, test_loader=None,
                 cold_protein_loader=None, cold_drug_loader=None, cold_all_loader=None):
        """
        åˆå§‹åŒ– DTAExperiment ç±»ã€‚

        :param config: é…ç½®å‚æ•°ï¼ŒåŒ…æ‹¬å­¦ä¹ ç‡ã€æ‰¹å¤§å°ç­‰
        :param model: è¦è®­ç»ƒçš„æ¨¡å‹
        :param train_loader: è®­ç»ƒæ•°æ®çš„ DataLoader
        :param val_loader: éªŒè¯æ•°æ®çš„ DataLoaderï¼ˆå¯é€‰ï¼‰
        :param test_loader: æµ‹è¯•æ•°æ®çš„ DataLoaderï¼ˆå¯é€‰ï¼‰
        :param cold_protein_loader: å†·å¯åŠ¨è›‹ç™½è´¨éªŒè¯é›†çš„ DataLoaderï¼ˆå¯é€‰ï¼‰
        :param cold_drug_loader: å†·å¯åŠ¨è¯ç‰©éªŒè¯é›†çš„ DataLoaderï¼ˆå¯é€‰ï¼‰
        :param cold_all_loader: å†·å¯åŠ¨å…¨æ•°æ®éªŒè¯é›†çš„ DataLoaderï¼ˆå¯é€‰ï¼‰
        """
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        self.timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        self.output_dir = os.path.join(config.output_dir, config.name)
        os.makedirs(self.output_dir, exist_ok=True)

        self.model = model.to(self.device)

        if self.device.type == "cuda":
            logical_id = self.device.index if self.device.index is not None else torch.cuda.current_device()
            gpu_name = torch.cuda.get_device_name(logical_id)
            print(f"âœ… Model loaded on device: cuda:{logical_id} ({gpu_name})")
        else:
            print("âœ… Model loaded on device: CPU")

        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr, weight_decay=config.weight_decay)
        self.scheduler = ReduceLROnPlateau(self.optimizer, mode='min', factor=0.1, patience=config.lr_scheduler_patience)

        self.trainer = Trainer(self.model, self.optimizer, device=self.device)
        self.evaluator = Evaluator(self.model, device=self.device)

        self.train_loader = train_loader
        self.val_loader = val_loader
        self.test_loader = test_loader
        self.cold_protein_loader = cold_protein_loader
        self.cold_drug_loader = cold_drug_loader
        self.cold_all_loader = cold_all_loader

        # ä½¿ç”¨ç¡¬ç¼–ç çš„æ¨¡å‹å‚æ•°
        self.model_save_paths = {
            'val': os.path.join(self.output_dir, "best_model_val.pth"),
            'test': os.path.join(self.output_dir, "best_model_test.pth")
        }

        self.best_mae_dict = {'val': float("inf")}
        self.early_stop_counter = 0
        self.early_stop_best_mae = float("inf")
        self.early_stopping_patience = config.early_stopping_patience

        self.epoch_csv_path = os.path.join(self.output_dir, f"{config.name}_epoch_metrics_{self.timestamp}.csv")
        self.final_csv_path = os.path.join(self.output_dir, f"{config.name}_final_metrics_{self.timestamp}.csv")

        print(f"\nğŸš€ Starting new experiment!")
        print(f"   ğŸ“‚ Dataset: {self.config.dataset}")
        print(f"   ğŸ’¾ Output Directory: {self.output_dir}")
        print(f"   ğŸ”§ Total Epochs: {self.config.epochs}")

    def train(self):
        with open(self.epoch_csv_path, "w", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(["Epoch", "Test Set", "MSE", "RMSE", "MAE", "R2", "PEARSON", "SPEARMAN", "CI", "RM2"])

        experiment_iter = tqdm(range(1, self.config.epochs + 1), desc="Training Progress", ncols=100)

        for epoch in experiment_iter:
            train_loss = self.trainer.train_epoch(self.train_loader)
            print(f"\nğŸ¯ Epoch {epoch}: ğŸ”§ Train Loss: {train_loss:.4f}")

            # æ ¹æ®æ•°æ®é›†åç§°åˆ¤æ–­æ˜¯å¦æ˜¯å†·å¯åŠ¨æ¨¡å¼
            if "cold_start" in self.config.dataset:
                self._evaluate_cold_start(epoch)
            else:
                self._evaluate_standard(epoch)

            # EarlyStoppingé€»è¾‘ (æŒ‰MAE)
            self._early_stopping(epoch)

    def _evaluate_cold_start(self, epoch):
        # ä»…åœ¨å†·å¯åŠ¨æ¨¡å¼ä¸‹éªŒè¯ï¼Œä¸å†è¿›è¡Œæµ‹è¯•é›†éªŒè¯
        for name, loader in [
            ('cold_protein', self.cold_protein_loader),
            ('cold_drug', self.cold_drug_loader),
            ('cold_all', self.cold_all_loader)
        ]:
            if loader is not None:
                val_metrics = self.evaluator.evaluate(loader)
                self._log_metrics(epoch, name, val_metrics)

                # ä¿å­˜æœ€ä½³æ¨¡å‹
                val_mae = val_metrics["MAE"]
                if val_mae < self.best_mae_dict.get(name, float("inf")):
                    self.best_mae_dict[name] = val_mae
                    torch.save(self.model.state_dict(), self.model_save_paths[name])
                    print(f"âœ… [{name}] Best model saved at epoch {epoch} with MAE={val_mae:.4f}")

    def _evaluate_standard(self, epoch):
        # ä»…åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå¹¶ä¿å­˜æœ€ä½³æ¨¡å‹
        val_metrics = self.evaluator.evaluate(self.val_loader)
        self._log_metrics(epoch, "val", val_metrics)

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        val_mae = val_metrics["MAE"]
        if val_mae < self.best_mae_dict.get('val', float("inf")):
            self.best_mae_dict['val'] = val_mae
            torch.save(self.model.state_dict(), self.model_save_paths['val'])  # ä¿å­˜åœ¨ val ç›®å½•
            print(f"âœ… [val] Best model saved at epoch {epoch} with MAE={val_mae:.4f}")

    def _log_metrics(self, epoch, test_name, val_metrics):
        with open(self.epoch_csv_path, "a", newline="") as f:
            writer = csv.writer(f)
            row = [epoch, test_name] + [f"{val_metrics[k]:.4f}" for k in ["MSE", "RMSE", "MAE", "R2", "PEARSON", "SPEARMAN", "CI", "RM2"]]
            writer.writerow(row)

    def _early_stopping(self, epoch):
        # EarlyStoppingé€»è¾‘ (æŒ‰MAE)
        monitored_mae = self.best_mae_dict.get('val', float("inf"))

        if monitored_mae < self.early_stop_best_mae:
            self.early_stop_best_mae = monitored_mae
            self.early_stop_counter = 0
        else:
            self.early_stop_counter += 1

        if self.early_stop_counter >= self.early_stopping_patience:
            print(f"\nğŸ›‘ Early stopping triggered after {epoch} epochs without improvement.")
            return

        self.scheduler.step(monitored_mae)

    def evaluate_final(self):
        if not self.test_loader:
            print("âš  No test set provided, skipping final evaluation.")
            return

        with open(self.final_csv_path, "w", newline="") as f:
            writer = csv.writer(f)
            header = ["Test Set", "MSE", "RMSE", "MAE", "R2", "PEARSON", "SPEARMAN", "CI", "RM2"]
            writer.writerow(header)

            # åŠ è½½æœ€ä½³æ¨¡å‹
            print(f"\nğŸ“¥ Loading best model for final evaluation ...")
            self.model.load_state_dict(torch.load(self.model_save_paths['val']))  # åŠ è½½éªŒè¯é›†çš„æœ€ä½³æ¨¡å‹

            # åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œè¯„ä¼°
            metrics = self.evaluator.evaluate(self.test_loader)
            print(f"ğŸ“Œ Final Test Metrics (test):")
            for k, v in metrics.items():
                print(f"   {k:>10}: {v:.4f}")

            writer.writerow(["test"] + [f"{metrics[k]:.4f}" for k in header[1:]])
